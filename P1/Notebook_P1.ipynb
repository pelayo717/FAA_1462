{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "from EstrategiaParticionado import ValidacionSimple\n",
    "from EstrategiaParticionado import ValidacionCruzada\n",
    "from Clasificador import ClasificadorNaiveBayes,Clasificador\n",
    "from Verificador import Verificador_GaussianNB, Verificador_Multinominal\n",
    "from MatrizConfusion import MatrizConfusion\n",
    "\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 1 => Particionado\n",
    "\n",
    "Análisis de las dos estrategias de particionado propuestas: simple, y\n",
    "cruzada, para los conjuntos propuestos: german y tic-tac-toe. El análisis\n",
    "consiste en una descripción de los índices de train y test devueltos por\n",
    "cada uno de los métodos de particionado, junto con un comentario\n",
    "sobre las ventajas/desventajas de cada uno de ellos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En cuanto al metodo de VALIDACIÓN SIMPLE es el mas sencillo de implementar, puesto que se basa en una division \n",
    "aleatoria en dos grupos. Sin embargo, aún siendo el modo de validación más sencillo, trae consigo una serie de\n",
    "inconvenientes:\n",
    "    \n",
    "    1) El ratio de error, es altamente variable dependiendo de las instancias del dataset escogido, para \n",
    "    entrenamiento, y test.\n",
    "    \n",
    "    2) Al segregar una serie de instancias para entrenamiento y test, estamos provocando que durante el entrenamiento\n",
    "    el clasificador, no contemple todas las posibles situaciones de un contexto, por lo tanto esto produce\n",
    "    una sobrestimación del ratio de error.\n",
    "    \n",
    "Por su parte el método de VALIDACIÓN CRUZADA es más complejo de implementar, puesto que se trata de un proceso \n",
    "iterativo. Éste, busca dividir todo el conjunto de datos en k grupos, de tal modo que, solo uno de esos bloques se usa \n",
    "como test, mientras que el resto de divisiones se usan como entrenamiento. Por cada iteración se turnan los \"roles\", de \n",
    "tal modo, que todas las subdivisiones son testadas y todas han sido usadas como entrenamiento. \n",
    "\n",
    "En un escenario, en el que el conjunto de datos es pequeño, es muy superior a validacón simple y otra ventaja \n",
    "respecto a validación simple es que, prueba y valida todas las instancias de datos. Por otra parte, podemos decir que\n",
    "el ratio de error en este tipo de validacion es mucho más preciso y real, puesto que se entrena con prácticamente todo\n",
    "el conjunto de datos maximizando asi el modelo sin sobrestimar en las predicciones. A su vez, es de gran\n",
    "utilidad el que el ratio de error sea calculado como un promedio de las estimaciones de cada iteración.\n",
    "\n",
    "Respecto los inconvenientes, principalmente encontramos uno, que es el coste computacional que requiere este método.\n",
    "La identificación de bloques, el número de iteraciones y sobre todo que en el caso de usar un dataset \n",
    "excesivamente grande, debemos contemplar la posibilidad de que se vuelva algo lento y costoso (en comparación con\n",
    "validación simple) y por tanto no sea tan útil como en otras circunstancias.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cambiar y poner bonito, pero lo necesito para el 2\"\"\"\n",
    "\n",
    "fileName = \"ConjuntosDatos/tic-tac-toe.data\"\n",
    "datos_tic = Datos(fileName)\n",
    "    \n",
    "    # Probamos con 75 porciento y 10 iteraciones (Validacion Simple)\n",
    "validacion_simple_tic = ValidacionSimple(75,10)\n",
    "aux_simple_tic = validacion_simple_tic.creaParticiones(datos_tic)\n",
    "\n",
    "    # Probamos con 10 k-iteraciones\n",
    "validacion_cruzada_tic = ValidacionCruzada(6)\n",
    "aux_cruzada_tic = validacion_cruzada_tic.creaParticiones(datos_tic)\n",
    "\n",
    "\n",
    "fileName = \"ConjuntosDatos/german.data\"\n",
    "datos_ger = Datos(fileName)\n",
    "\n",
    "    # Probamos con 75 porciento y 10 iteraciones (Validacion Simple)\n",
    "validacion_simple_ger = ValidacionSimple(75,10)\n",
    "aux_simple_ger = validacion_simple_ger.creaParticiones(datos_ger)\n",
    "\n",
    "# Probamos con 10 k-iteraciones\n",
    "validacion_cruzada_ger = ValidacionCruzada(6)\n",
    "aux_cruzada_ger = validacion_cruzada_ger.creaParticiones(datos_ger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 2 => Naive Bayes\n",
    "\n",
    "Tabla con los resultados de la ejecución para los conjuntos de datos\n",
    "analizados (tic-tac-toe y german). Considerar los dos tipos de\n",
    "particionado.\n",
    "Los resultados se refieren a las tasas de error/acierto y deben incluirse\n",
    "tanto con la corrección de Laplace como sin ella. Se debe incluir tanto\n",
    "el promedio de error para las diferentes particiones como su desviación\n",
    "típica. Es importante mostrar todos los resultados agrupados en una\n",
    "tabla para facilitar su evaluación.\n",
    "Breve análisis de los resultados anteriores.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Como se puede observar en las tablas generadas, se cumple lo dicho en el apartado anterior, siendo el error medio de la validación cruzada más bajo que el de la simple. De lo cual se peude deducir que la validación cruzada es más percisa.\n",
    "\n",
    " Además, cabe destacar las diferencias entre ejecutar la validación sin y con la corrección de Laplace. En estos datasets pequeños, no parece que se aprecie mucha diferencia, pero si nos fijamos en la validación cruzada, veremos que en 'German' sí que nos cambia, subiendo un poco la tasa de error medio. Esto puede ser causado por la generación de ejemplos que no se encuentran en el dataset que realiza la correcciónd de Laplace para eliminar valores nulos de las tablas de atributos.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del clasificador\n",
    "Clasificador = ClasificadorNaiveBayes()\n",
    "\n",
    "#       Sin Laplace\n",
    "#  TIC TAC TOE\n",
    "# Validacion con validacion simple\n",
    "media_error1, media_tp1, media_fp1, media_tn1, media_fn1 = Clasificador.validacion(validacion_simple_tic,datos_tic,False)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error2, media_tp2, media_fp2, media_tn2, media_fn2 = Clasificador.validacion(validacion_cruzada_tic,datos_tic,False)\n",
    "\n",
    "#  GERMAN  \n",
    "# Validacion con validacion simple\n",
    "media_error3, media_tp3, media_fp3, media_tn3, media_fn3 = Clasificador.validacion(validacion_simple_ger,datos_ger,False)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error4, media_tp4, media_fp4, media_tn4, media_fn4 = Clasificador.validacion(validacion_cruzada_ger,datos_ger,False)\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados = [[round(media_error1, 3), round(media_error3, 3)], [round(media_error2, 3), \n",
    "round(media_error4, 3)]]\n",
    "\n",
    "print(\"Sin Laplace\")\n",
    "print(tabulate(resultados, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n",
    "\n",
    "#       Con Laplace\n",
    "#  TIC TAC TOE\n",
    "# Validacion con validacion simple\n",
    "media_error1, media_tp1, media_fp1, media_tn1, media_fn1 = Clasificador.validacion(validacion_simple_tic,datos_tic,True)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error2, media_tp2, media_fp2, media_tn2, media_fn2 = Clasificador.validacion(validacion_cruzada_tic,datos_tic,True)\n",
    "\n",
    "#  GERMAN  \n",
    "# Validacion con validacion simple\n",
    "media_error3, media_tp3, media_fp3, media_tn3, media_fn3 = Clasificador.validacion(validacion_simple_ger,datos_ger,True)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error4, media_tp4, media_fp4, media_tn4, media_fn4 = Clasificador.validacion(validacion_cruzada_ger,datos_ger,True)\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados = [[round(media_error1, 3), round(media_error3, 3)], [round(media_error2, 3), \n",
    "round(media_error4, 3)]]\n",
    "print(\"Con Laplace\")\n",
    "print(tabulate(resultados, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 3 => Evaluación de hipótesis mediante Análisis ROC\n",
    "Matriz de confusión y diagramas del clasificador en el espacio ROC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En cuanto a la matriz de confusión, podemos observar que en ambos casos la clase positiva es mucho más abundante en el dataset que la negativa, por tanto los números de la primera fila son más altos.\n",
    "\n",
    "En segundo lugar, cabe destacar que la cantidad de aciertos en ambas es bastante mayor que el de fallos,lo que se traduce en una predicción por encima de la diagonal normal.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la media de las tasas de val. simple y val. cruzada para la matriz de confusion media\n",
    "    mx1 = MatrizConfusion()\n",
    "\n",
    "    # TIC-TAC-TOE\n",
    "    print(\"\\nTic-Tac-Toe\\n\")\n",
    "    tpr, fpr = mx1.matrix_media(media_tp1, media_tp2, media_fp1, media_fp2, \n",
    "                    media_tn1, media_tn2, media_fn1, media_fn2)\n",
    "    plot_points = [[fpr, tpr, 'NB']]\n",
    "    mx1.plot(plot_points, \"tic-tac-toe\")\n",
    "\n",
    "    # GERMAN\n",
    "    print(\"\\nGerman\\n\")\n",
    "\n",
    "    tpr, fpr = mx1.matrix_media(media_tp3, media_tp4, media_fp3, media_fp4, \n",
    "                    media_tn3, media_tn4, media_fn3, media_fn4)\n",
    "    plot_points = [[fpr, tpr, 'NB']]\n",
    "    mx1.plot(plot_points, \"german\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit76353b65c158435a8fb60224477d79b6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}