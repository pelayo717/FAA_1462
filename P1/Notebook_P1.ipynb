{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2042f24db98b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMatrizConfusion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatrizConfusion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "from Datos import Datos\n",
    "from EstrategiaParticionado import ValidacionSimple\n",
    "from EstrategiaParticionado import ValidacionCruzada\n",
    "from Clasificador import ClasificadorNaiveBayes,Clasificador\n",
    "from Verificador import Verificador_GaussianNB, Verificador_Multinominal\n",
    "from MatrizConfusion import MatrizConfusion\n",
    "\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 1 => Particionado\n",
    "\n",
    "Análisis de las dos estrategias de particionado propuestas: simple, y\n",
    "cruzada, para los conjuntos propuestos: german y tic-tac-toe. El análisis\n",
    "consiste en una descripción de los índices de train y test devueltos por\n",
    "cada uno de los métodos de particionado, junto con un comentario\n",
    "sobre las ventajas/desventajas de cada uno de ellos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En cuanto al metodo de VALIDACIÓN SIMPLE es el mas sencillo de implementar, puesto que se basa en una division \n",
    "aleatoria en dos grupos. Sin embargo, aún siendo el modo de validación más sencillo, trae consigo una serie de\n",
    "inconvenientes:\n",
    "    \n",
    "    1) El ratio de error, es altamente variable dependiendo de las instancias del dataset escogido, para \n",
    "    entrenamiento, y test.\n",
    "    \n",
    "    2) Al segregar una serie de instancias para entrenamiento y test, estamos provocando que durante el entrenamiento\n",
    "    el clasificador, no contemple todas las posibles situaciones de un contexto, por lo tanto esto produce\n",
    "    una sobrestimación del ratio de error.\n",
    "    \n",
    "Por su parte el método de VALIDACIÓN CRUZADA es más complejo de implementar, puesto que se trata de un proceso \n",
    "iterativo. Éste, busca dividir todo el conjunto de datos en k grupos, de tal modo que, solo uno de esos bloques se usa \n",
    "como test, mientras que el resto de divisiones se usan como entrenamiento. Por cada iteración se turnan los \"roles\", de \n",
    "tal modo, que todas las subdivisiones son testadas y todas han sido usadas como entrenamiento. \n",
    "\n",
    "En un escenario, en el que el conjunto de datos es pequeño, es muy superior a validacón simple y otra ventaja \n",
    "respecto a validación simple es que, prueba y valida todas las instancias de datos. Por otra parte, podemos decir que\n",
    "el ratio de error en este tipo de validacion es mucho más preciso y real, puesto que se entrena con prácticamente todo\n",
    "el conjunto de datos maximizando asi el modelo sin sobrestimar en las predicciones. A su vez, es de gran\n",
    "utilidad el que el ratio de error sea calculado como un promedio de las estimaciones de cada iteración.\n",
    "\n",
    "Respecto los inconvenientes, principalmente encontramos uno, que es el coste computacional que requiere este método.\n",
    "La identificación de bloques, el número de iteraciones y sobre todo que en el caso de usar un dataset \n",
    "excesivamente grande, debemos contemplar la posibilidad de que se vuelva algo lento y costoso (en comparación con\n",
    "validación simple) y por tanto no sea tan útil como en otras circunstancias.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje entrenamiento: 75\n",
      "Numero iteraciones: 10 <=> Numero particiones: 10\n",
      "Indices Totales(Primera Iteracion/Particion) => 958\n",
      "\tNum Indices Train: 719\n",
      "\tNum Indices Test: 239\n",
      "Numero Carpetas: 6 <=> Numero particiones: 6\n",
      "Indices Totales(Primera Iteracion/Particion) => 958\n",
      "158\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cambiar y poner bonito, pero lo necesito para el 2\"\"\"\n",
    "\n",
    "fileName = \"ConjuntosDatos/tic-tac-toe.data\"\n",
    "datos_tic = Datos(fileName)\n",
    "    \n",
    "    # Probamos con 75 porciento y 10 iteraciones (Validacion Simple)\n",
    "validacion_simple_tic = ValidacionSimple(75,10)\n",
    "aux_simple_tic = validacion_simple_tic.creaParticiones(datos_tic)\n",
    "\n",
    "print(\"Porcentaje entrenamiento: \" + str(validacion_simple_tic.porcentaje))\n",
    "print(\"Numero iteraciones: \" + str(validacion_simple_tic.numEjecuciones) + \" <=> Numero particiones: \" + str(len(aux_simple_tic)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_tic.cantidadDatos))\n",
    "print(\"\\tNum Indices Train: \" + str(len(aux_simple_tic[0].indicesTrain)))\n",
    "print(\"\\tNum Indices Test: \" + str(len(aux_simple_tic[0].indicesTest)))\n",
    "\n",
    "    # Probamos con 10 k-iteraciones\n",
    "validacion_cruzada_tic = ValidacionCruzada(6)\n",
    "aux_cruzada_tic = validacion_cruzada_tic.creaParticiones(datos_tic)\n",
    "\n",
    "print(\"Numero Carpetas: \" + str(validacion_cruzada_tic.numParticiones) + \" <=> Numero particiones: \" + str(len(aux_cruzada_tic)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_tic.cantidadDatos))\n",
    "print(len(aux_cruzada_tic[0].indicesTrain))\n",
    "print(len(aux_cruzada_tic[0].indicesTest))\n",
    "\n",
    "fileName = \"ConjuntosDatos/german.data\"\n",
    "datos_ger = Datos(fileName)\n",
    "\n",
    "    # Probamos con 75 porciento y 10 iteraciones (Validacion Simple)\n",
    "validacion_simple_ger = ValidacionSimple(75,10)\n",
    "aux_simple_ger = validacion_simple_ger.creaParticiones(datos_ger)\n",
    "\n",
    "# Probamos con 10 k-iteraciones\n",
    "validacion_cruzada_ger = ValidacionCruzada(6)\n",
    "aux_cruzada_ger = validacion_cruzada_ger.creaParticiones(datos_ger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 2 => Naive Bayes\n",
    "\n",
    "Tabla con los resultados de la ejecución para los conjuntos de datos\n",
    "analizados (tic-tac-toe y german). Considerar los dos tipos de\n",
    "particionado.\n",
    "Los resultados se refieren a las tasas de error/acierto y deben incluirse\n",
    "tanto con la corrección de Laplace como sin ella. Se debe incluir tanto\n",
    "el promedio de error para las diferentes particiones como su desviación\n",
    "típica. Es importante mostrar todos los resultados agrupados en una\n",
    "tabla para facilitar su evaluación.\n",
    "Breve análisis de los resultados anteriores.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Como se puede observar en las tablas generadas, se cumple lo dicho en el apartado anterior, \n",
    " siendo el error medio de la validación cruzada más bajo que el de la simple. De lo cual se puede deducir que la \n",
    " validación cruzada es más precisa.\n",
    "\n",
    " Además, cabe destacar las diferencias entre ejecutar, la validación sin y con la corrección de Laplace. \n",
    " En estos datasets pequeños, no parece que se aprecie mucha diferencia, pero si nos fijamos en la validación cruzada,\n",
    " veremos que en 'German' sí que nos cambia, subiendo un poco la tasa de error medio. \n",
    " Esto puede ser causado por la generación de ejemplos que no se encuentran en el dataset que realiza la corrección \n",
    " de Laplace para eliminar valores nulos de las tablas de atributos.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validacion_simple_tic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6a9609e4faaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#  TIC-TAC-TOE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Validacion con validacion simple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmedia_error1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedia_tp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedia_fp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedia_tn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedia_fn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClasificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidacion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidacion_simple_tic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatos_tic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Validacion con validacion cruzada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validacion_simple_tic' is not defined"
     ]
    }
   ],
   "source": [
    "# Creacion del clasificador\n",
    "Clasificador = ClasificadorNaiveBayes()\n",
    "\n",
    "#       Sin Laplace\n",
    "#  TIC-TAC-TOE\n",
    "# Validacion con validacion simple\n",
    "media_error1, media_tp1, media_fp1, media_tn1, media_fn1 = Clasificador.validacion(validacion_simple_tic,datos_tic,False)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error2, media_tp2, media_fp2, media_tn2, media_fn2 = Clasificador.validacion(validacion_cruzada_tic,datos_tic,False)\n",
    "\n",
    "#  GERMAN  \n",
    "# Validacion con validacion simple\n",
    "media_error3, media_tp3, media_fp3, media_tn3, media_fn3 = Clasificador.validacion(validacion_simple_ger,datos_ger,False)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error4, media_tp4, media_fp4, media_tn4, media_fn4 = Clasificador.validacion(validacion_cruzada_ger,datos_ger,False)\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados = [[round(media_error1, 3), round(media_error3, 3)], [round(media_error2, 3), \n",
    "round(media_error4, 3)]]\n",
    "\n",
    "print(\"Sin Laplace\")\n",
    "print(tabulate(resultados, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n",
    "\n",
    "#       Con Laplace\n",
    "#  TIC-TAC-TOE\n",
    "# Validacion con validacion simple\n",
    "media_error1, media_tp1, media_fp1, media_tn1, media_fn1 = Clasificador.validacion(validacion_simple_tic,datos_tic,True)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error2, media_tp2, media_fp2, media_tn2, media_fn2 = Clasificador.validacion(validacion_cruzada_tic,datos_tic,True)\n",
    "\n",
    "#  GERMAN  \n",
    "# Validacion con validacion simple\n",
    "media_error3, media_tp3, media_fp3, media_tn3, media_fn3 = Clasificador.validacion(validacion_simple_ger,datos_ger,True)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error4, media_tp4, media_fp4, media_tn4, media_fn4 = Clasificador.validacion(validacion_cruzada_ger,datos_ger,True)\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados = [[round(media_error1, 3), round(media_error3, 3)], [round(media_error2, 3), \n",
    "round(media_error4, 3)]]\n",
    "print(\"Con Laplace\")\n",
    "print(tabulate(resultados, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aparto 3 => Scikit-Learn\n",
    "Incluir los mismos resultados que en el apartado 2 pero usando los\n",
    "métodos del paquete scikit-learn. Comparar y analizar los resultados. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    " Para llevar a cabo la verificación de nuestros clasificadores implementados usamos la libreria scikitlearn, \n",
    " de la cual usamos varias funciones de clasificación, varias de metodos de validación y varias de preprocesado de datos.\n",
    " Para empezar, hemos desarrollado dos funciones propias de la clase abstracta Verificador, \n",
    " las cuales se encargana de llevar a cabo un preprocesado similar al que desarrollamos en la primera entrega, \n",
    " y por otra parte hemos desarrollado un preprocesado OneHot que nos ha proporcionado muy buenos resultados. \n",
    " \n",
    " Por otro lado, implementamos una función muy pequeña que se encarga de separar los datos de entrada y los de clasificación\n",
    " y almacenarnos en estructuras diferentes. \n",
    " Por último, como funciones abstractas desarrollamos dos métodos de validación (validación simple y validación cruzada).\n",
    "\n",
    " En cuanto a las subclases que encontramos, hemos decidido implementar tanto el clasififcador GaussianNB como el MultinominalNB. \n",
    " Ambas se pueden configurar mediante hiperparametros, y aunque ambas nos han devuelto resultados muy buenos \n",
    " en la siguiente implementación hemos decidido usar únicamente el GaussianNB, puesto que es el que mejor ha \n",
    " respondido a los datasets proporcinados.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB => Sin Preprocesad\n",
      "\n",
      "\tTIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\n",
      "\tVerificador GaussianNB ==> Error medio Simple (0.266667) en archivo ConjuntosDatos/tic-tac-toe.data\n",
      "\n",
      "\tTIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\n",
      "\tVerificador GaussianNB ==> Error medio Cruzado (0.366388) en archivo ConjuntosDatos/tic-tac-toe.data\n",
      "\n",
      "\tGERMAN => Validacion Cruzada (TRAIN = 0.75)\n",
      "\tVerificador GaussianNB ==> Error medio Simple (0.288000) en archivo ConjuntosDatos/german.data\n",
      "\n",
      "\tGERMAN => Validacion Cruzada (KFOLDS = 6)\n",
      "\tVerificador GaussianNB ==> Error medio Cruzado (0.264000) en archivo ConjuntosDatos/german.data\n",
      "\n",
      "\tTIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\n",
      "\tVerificador GaussianNB ==> Error medio Simple (0.000000) en archivo ConjuntosDatos/tic-tac-toe.data\n",
      "\n",
      "\tTIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\n",
      "\tVerificador GaussianNB ==> Error medio Cruzado (0.000000) en archivo ConjuntosDatos/tic-tac-toe.data\n",
      "\n",
      "\tGERMAN => Validacion Cruzada (TRAIN = 0.75)\n",
      "\tVerificador GaussianNB ==> Error medio Simple (0.032000) en archivo ConjuntosDatos/german.data\n",
      "\n",
      "\tGERMAN => Validacion Cruzada (KFOLDS = 6)\n",
      "\tVerificador GaussianNB ==> Error medio Cruzado (0.027000) en archivo ConjuntosDatos/german.data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Verificador.Verificador_GaussianNB at 0x1097a2e50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# GaussianNB => Sin Preprocesado\n",
    "print(\"GaussianNB => Sin Preprocesad\")\n",
    "#     TIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\n",
    "print(\"\\n\\tTIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\")\n",
    "Verificador_GaussianNB(prepro=False,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "#     TIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\n",
    "print(\"\\n\\tTIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\")\n",
    "Verificador_GaussianNB(prepro=False,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "\n",
    "#     GERMAN => Validacion Simple (TRAIN=0.75)\n",
    "print(\"\\n\\tGERMAN => Validacion Cruzada (TRAIN = 0.75)\")\n",
    "Verificador_GaussianNB(prepro=False,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/german.data\")\n",
    "#     GERMAN => Validacion Cruzada (KFOLDS = 6)\n",
    "print(\"\\n\\tGERMAN => Validacion Cruzada (KFOLDS = 6)\")\n",
    "Verificador_GaussianNB(prepro=False,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/german.data\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GaussianNB => Con Preprocesado\n",
    "\n",
    "#     TIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\n",
    "print(\"\\n\\tTIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\")\n",
    "Verificador_GaussianNB(prepro=True,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "#     TIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\n",
    "print(\"\\n\\tTIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\")\n",
    "Verificador_GaussianNB(prepro=True,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "\n",
    "#     GERMAN => Validacion Simple (TRAIN=0.75)\n",
    "print(\"\\n\\tGERMAN => Validacion Cruzada (TRAIN = 0.75)\")\n",
    "Verificador_GaussianNB(prepro=True,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/german.data\")\n",
    "#     GERMAN => Validacion Cruzada (KFOLDS = 6)\n",
    "print(\"\\n\\tGERMAN => Validacion Cruzada (KFOLDS = 6)\")\n",
    "Verificador_GaussianNB(prepro=True,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/german.data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n Para validar los resultados debemos conocer la importancia y efectividad del preprocesado OneHot, ideal para tablas\\n dataset\\'s que albergan pocas columnas. Este tipo de preprocesado usa las columnas y sus posibles valores para reconstruir el\\n dataset con tantas columnas como [Sumatorio{Columna(i) * #Valores(Columna(i))}]. Esto nos permite que teniendo el mismo\\n numero de entradas en el dataset, podamos tener una codificacion mucho más concreta y por ende facilitemos la labor al\\n clasificador puesto que ahora las entradas se codifican de modo binario. \\n \\n Conociendo esta situación vemos como todas aquellas pruebas realizadas tanto en un fichero como en otro, son mucho\\n mejores que sin aplicar un preprocesado OneHot. Por otra parte vemos como la validación simple es mucho mejor en cuanto\\n al error medio presentado con validacion cruzada y además vemos que la clasificación en general se realiza de mejor manera\\n para el fichero tic-tac-toe.dat que para el fichero german.data, posiblemente porque este ultimo contiene más registros\\n y más columnas.\\n \\n Como hiperparametros, hemos empleado 0.75 para el entrenamiento en validación simple y 6 Kfolds para validación cruzada.\\n En cuanto al primero, consideramos un porcentaje de entrenamiento lo suficientemente grande como para no sobreestimar en\\n la clasififcación y para asi garantizar esa capacidad de geeneralizar frente los datos a clasificar.\\n \\n En cuanto al segundo hiperparametro lo consideramos algo pequeño, para estos dataset. Hemos probado a aumentar este número\\n de bloques y hemos observado que a medida que aumentaba el error medio disminuia. Podemos afirmar, que para tic-tac-toe.data\\n un \"correcto\" número de carpetas sería 12, mientras que para german.data este sería de \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " Para validar los resultados debemos conocer la importancia y efectividad del preprocesado OneHot, ideal para tablas\n",
    " dataset's que albergan pocas columnas. Este tipo de preprocesado usa las columnas y sus posibles valores para reconstruir el\n",
    " dataset con tantas columnas como [Sumatorio{Columna(i) * #Valores(Columna(i))}]. Esto nos permite que teniendo el mismo\n",
    " numero de entradas en el dataset, podamos tener una codificacion mucho más concreta y por ende facilitemos la labor al\n",
    " clasificador puesto que ahora las entradas se codifican de modo binario. \n",
    " \n",
    " Conociendo esta situación vemos como todas aquellas pruebas realizadas tanto en un fichero como en otro, son mucho\n",
    " mejores que sin aplicar un preprocesado OneHot. Por otra parte vemos como la validación simple es mucho mejor en cuanto\n",
    " al error medio presentado con validacion cruzada y además vemos que la clasificación en general se realiza de mejor manera\n",
    " para el fichero tic-tac-toe.dat que para el fichero german.data, posiblemente porque este ultimo contiene más registros\n",
    " y más columnas.\n",
    " \n",
    " Como hiperparametros, hemos empleado 0.75 para el entrenamiento en validación simple y 6 Kfolds para validación cruzada.\n",
    " En cuanto al primero, consideramos un porcentaje de entrenamiento lo suficientemente grande como para no sobreestimar en\n",
    " la clasififcación y para asi garantizar esa capacidad de geeneralizar frente los datos a clasificar.\n",
    " \n",
    " En cuanto al segundo hiperparametro lo consideramos algo pequeño, para estos dataset. Hemos probado a aumentar este número\n",
    " de bloques y hemos observado que a medida que aumentaba el error medio disminuia. Podemos afirmar, que para tic-tac-toe.data\n",
    " un \"correcto\" número de carpetas sería 12, mientras que para german.data este sería de 10 carpetas.\n",
    " \n",
    " Aún con estas modificaciones, error nos disminuye considerablemente, pero si consideramos un método de estimar cuantas\n",
    " carpetas son necesarias dado el volumen y las condiciones de un dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 4 => Evaluación de hipótesis mediante Análisis ROC\n",
    "Matriz de confusión y diagramas del clasificador en el espacio ROC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En cuanto a la matriz de confusión, podemos observar que en ambos casos la clase positiva es mucho más abundante en el dataset que la negativa, por tanto los números de la primera fila son más altos.\n",
    "\n",
    "En segundo lugar, cabe destacar que la cantidad de aciertos en ambas es bastante mayor que el de fallos,lo que se traduce en una predicción por encima de la diagonal normal.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la media de las tasas de val. simple y val. cruzada para la matriz de confusion media\n",
    "    mx1 = MatrizConfusion()\n",
    "\n",
    "    # TIC-TAC-TOE\n",
    "    print(\"\\nTic-Tac-Toe\\n\")\n",
    "    tpr, fpr = mx1.matrix_media(media_tp1, media_tp2, media_fp1, media_fp2, \n",
    "                    media_tn1, media_tn2, media_fn1, media_fn2)\n",
    "    plot_points = [[fpr, tpr, 'NB']]\n",
    "    mx1.plot(plot_points, \"tic-tac-toe\")\n",
    "\n",
    "    # GERMAN\n",
    "    print(\"\\nGerman\\n\")\n",
    "\n",
    "    tpr, fpr = mx1.matrix_media(media_tp3, media_tp4, media_fp3, media_fp4, \n",
    "                    media_tn3, media_tn4, media_fn3, media_fn4)\n",
    "    plot_points = [[fpr, tpr, 'NB']]\n",
    "    mx1.plot(plot_points, \"german\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
