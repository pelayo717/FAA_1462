{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "from EstrategiaParticionado import ValidacionSimple\n",
    "from EstrategiaParticionado import ValidacionCruzada\n",
    "from Clasificador import ClasificadorNaiveBayes,Clasificador\n",
    "from Verificador import Verificador_GaussianNB, Verificador_Multinominal\n",
    "from MatrizConfusion import MatrizConfusion\n",
    "\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 1 => Particionado\n",
    "\n",
    "Análisis de las dos estrategias de particionado propuestas: simple, y\n",
    "cruzada, para los conjuntos propuestos: german y tic-tac-toe. El análisis\n",
    "consiste en una descripción de los índices de train y test devueltos por\n",
    "cada uno de los métodos de particionado, junto con un comentario\n",
    "sobre las ventajas/desventajas de cada uno de ellos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En cuanto al metodo de VALIDACIÓN SIMPLE es el mas sencillo de implementar, puesto que se basa en una division \n",
    "aleatoria en dos grupos. Sin embargo, aún siendo el modo de validación más sencillo, trae consigo una serie de\n",
    "inconvenientes:\n",
    "    \n",
    "    1) El ratio de error, es altamente variable dependiendo de las instancias del dataset escogido, para \n",
    "    entrenamiento, y test.\n",
    "    \n",
    "    2) Al segregar una serie de instancias para entrenamiento y test, estamos provocando que durante el entrenamiento\n",
    "    el clasificador, no contemple todas las posibles situaciones de un contexto, por lo tanto esto produce\n",
    "    una sobrestimación del ratio de error.\n",
    "    \n",
    "Por su parte el método de VALIDACIÓN CRUZADA es más complejo de implementar, puesto que se trata de un proceso \n",
    "iterativo. Éste, busca dividir todo el conjunto de datos en k grupos, de tal modo que, solo uno de esos bloques se usa \n",
    "como test, mientras que el resto de divisiones se usan como entrenamiento. Por cada iteración se turnan los \"roles\", de \n",
    "tal modo, que todas las subdivisiones son testadas y todas han sido usadas como entrenamiento. \n",
    "\n",
    "En un escenario, en el que el conjunto de datos es pequeño, es muy superior a validacón simple y otra ventaja \n",
    "respecto a validación simple es que, prueba y valida todas las instancias de datos. Por otra parte, podemos decir que\n",
    "el ratio de error en este tipo de validacion es mucho más preciso y real, puesto que se entrena con prácticamente todo\n",
    "el conjunto de datos maximizando asi el modelo sin sobrestimar en las predicciones. A su vez, es de gran\n",
    "utilidad el que el ratio de error sea calculado como un promedio de las estimaciones de cada iteración.\n",
    "\n",
    "Respecto los inconvenientes, principalmente encontramos uno, que es el coste computacional que requiere este método.\n",
    "La identificación de bloques, el número de iteraciones y sobre todo que en el caso de usar un dataset \n",
    "excesivamente grande, debemos contemplar la posibilidad de que se vuelva algo lento y costoso (en comparación con\n",
    "validación simple) y por tanto no sea tan útil como en otras circunstancias.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"ConjuntosDatos/tic-tac-toe.data\"\n",
    "datos_tic = Datos(fileName)\n",
    "    \n",
    "    # Probamos con 75 porciento y 10 iteraciones (Validacion Simple)\n",
    "validacion_simple_tic = ValidacionSimple(75,10)\n",
    "aux_simple_tic = validacion_simple_tic.creaParticiones(datos_tic)\n",
    "\n",
    "print(\"######## VALIDACION SIMPLE TIC-TAC-TOE ########\")\n",
    "print(\"Porcentaje entrenamiento: \" + str(validacion_simple_tic.porcentaje))\n",
    "print(\"Numero iteraciones: \" + str(validacion_simple_tic.numEjecuciones) + \" <=> Numero particiones: \" + str(len(aux_simple_tic)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_tic.cantidadDatos))\n",
    "print(\"\\tNum Indices Train: \" + str(len(aux_simple_tic[0].indicesTrain)))\n",
    "print(\"\\tNum Indices Test: \" + str(len(aux_simple_tic[0].indicesTest)))\n",
    "\n",
    "    # Probamos con 10 k-iteraciones\n",
    "validacion_cruzada_tic = ValidacionCruzada(6)\n",
    "aux_cruzada_tic = validacion_cruzada_tic.creaParticiones(datos_tic)\n",
    "\n",
    "print(\"\\n######## VALIDACION CRUZADA TIC-TAC-TOE ########\")\n",
    "print(\"Numero Carpetas: \" + str(validacion_cruzada_tic.numParticiones) + \" <=> Numero particiones: \" + str(len(aux_cruzada_tic)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_tic.cantidadDatos))\n",
    "print(\"\\tNum Indices Train: \" + str(len(aux_cruzada_tic[0].indicesTrain)))\n",
    "print(\"\\tNum Indices Test: \" + str(len(aux_cruzada_tic[0].indicesTest)))\n",
    "\n",
    "fileName = \"ConjuntosDatos/german.data\"\n",
    "datos_ger = Datos(fileName)\n",
    "\n",
    "    # Probamos con 75 porciento y 10 iteraciones (Validacion Simple)\n",
    "validacion_simple_ger = ValidacionSimple(75,10)\n",
    "aux_simple_ger = validacion_simple_ger.creaParticiones(datos_ger)\n",
    "\n",
    "print(\"\\n######## VALIDACIONES GERMAN ########\")\n",
    "print(\"Porcentaje entrenamiento: \" + str(validacion_simple_ger.porcentaje))\n",
    "print(\"Numero iteraciones: \" + str(validacion_simple_ger.numEjecuciones) + \" <=> Numero particiones: \" + str(len(aux_simple_ger)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_ger.cantidadDatos))\n",
    "print(\"\\tNum Indices Train: \" + str(len(aux_simple_ger[0].indicesTrain)))\n",
    "print(\"\\tNum Indices Test: \" + str(len(aux_simple_ger[0].indicesTest)))\n",
    "\n",
    "# Probamos con 10 k-iteraciones\n",
    "validacion_cruzada_ger = ValidacionCruzada(6)\n",
    "aux_cruzada_ger = validacion_cruzada_ger.creaParticiones(datos_ger)\n",
    "print(\"\\n######## VALIDACION CRUZADA GERMAN ########\")\n",
    "print(\"Numero Carpetas: \" + str(validacion_cruzada_ger.numParticiones) + \" <=> Numero particiones: \" + str(len(aux_cruzada_ger)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_ger.cantidadDatos))\n",
    "print(\"\\tNum Indices Train: \" + str(len(aux_cruzada_ger[0].indicesTrain)))\n",
    "print(\"\\tNum Indices Test: \" + str(len(aux_cruzada_ger[0].indicesTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Como vemos, hemos representado dos particiones para cada dataset empleado en la práctica.\n",
    "Las validaciones simples hemos almacenado el numero de iteraciones que para ambas pruebas ha sido de 10.\n",
    "En cada iteración, que corresponde a su vez a una particion, almacenamos de modo aleatorio el número de indices \n",
    "especificado por el usuario en forma de porcentaje (para nuestro ejemplo, se trata de un 0.75).\n",
    "\n",
    "En cuanto a la validación cruzada, preparamos a priori, cada bloque con el número de indices que le corresponde.\n",
    "Para el caso de tic-tac-toe.data, estamos usando un total de 958 entradas en el datset que se reparten entre 6 bloques\n",
    "con 158-160 indices. Como vemos el número de indices varia, dependiendo de la situación y de si el total de indices, es\n",
    "divisible (con resto 0) wntre el número de bloques (Kfolds) que escogio el usuario.\n",
    "\n",
    "Tras ello, procedemos a insertar los indices de cada bloque en los array's de indicesTrain, e indicesTest, y tenemos en\n",
    "cuenta, que bloque ha sido de test en cada iteración, para en cada una, escoger uno diferente y asignar el resto de\n",
    "bloques como datos de train.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 2 => Naive Bayes\n",
    "\n",
    "Tabla con los resultados de la ejecución para los conjuntos de datos\n",
    "analizados (tic-tac-toe y german). Considerar los dos tipos de\n",
    "particionado.\n",
    "Los resultados se refieren a las tasas de error/acierto y deben incluirse\n",
    "tanto con la corrección de Laplace como sin ella. Se debe incluir tanto\n",
    "el promedio de error para las diferentes particiones como su desviación\n",
    "típica. Es importante mostrar todos los resultados agrupados en una\n",
    "tabla para facilitar su evaluación.\n",
    "Breve análisis de los resultados anteriores.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "El objetivo de este apartado es crear el modelos Naive Bayes que se entrene con los ejemplos indexados  por 'train' generados en el apartado anterior y que clasifique aquellos marcados por los indices 'test' tambien porporcionados por los validadores.\n",
    "\n",
    "El modo de clasificación de Naive Bayes trae consigo una premisa que hace que su implementación sea más sencilla. Esta es la suposición de que los atributos del dataset son independientes unos de otros dada la clase. \n",
    "\n",
    "Como ventaja, la independencia de atributos, nos trae que se puede crear un modelo potente, con relativamente poco coste computacional y que es facilmente escalable en cuanto a atributos se refiere. Esto quiere decir que el coste computacional es lineal.\n",
    "\n",
    "Como inconveniente, la premisa de la que se parte es demasiado optimista, pues en muchas ocasiones ciertos atributos del dataset pueden estar relacionados con otros. Por ejemplo en un dataset con un atributo \"nubes\" (sí/no) y otro \"lluvia\" (sí/no) hay una clara relación puesto que si no hay nubes tampoco hay lluvia. Con esto se quiere decir que un modelo que tenga en cuentas esta dependecia de atributos será más preciso que NB, o lo que es lo mismo, NB pierde precisión al suponer la independecia entre atributos.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del clasificador\n",
    "Clasificador = ClasificadorNaiveBayes()\n",
    "\n",
    "#       Sin Laplace\n",
    "#  TIC-TAC-TOE\n",
    "# Validacion con validacion simple\n",
    "media_error1, media_tp1, media_fp1, media_tn1, media_fn1 = Clasificador.validacion(validacion_simple_tic,datos_tic,False)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error2, media_tp2, media_fp2, media_tn2, media_fn2 = Clasificador.validacion(validacion_cruzada_tic,datos_tic,False)\n",
    "\n",
    "#  GERMAN  \n",
    "# Validacion con validacion simple\n",
    "media_error3, media_tp3, media_fp3, media_tn3, media_fn3 = Clasificador.validacion(validacion_simple_ger,datos_ger,False)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error4, media_tp4, media_fp4, media_tn4, media_fn4 = Clasificador.validacion(validacion_cruzada_ger,datos_ger,False)\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados_sin = [[round(media_error1, 3), round(media_error3, 3)], [round(media_error2, 3), \n",
    "round(media_error4, 3)]]\n",
    "\n",
    "print(\"Sin Laplace\")\n",
    "print(tabulate(resultados_sin, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n",
    "\n",
    "#       Con Laplace\n",
    "#  TIC-TAC-TOE\n",
    "# Validacion con validacion simple\n",
    "media_error1, media_tp1, media_fp1, media_tn1, media_fn1 = Clasificador.validacion(validacion_simple_tic,datos_tic,True)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error2, media_tp2, media_fp2, media_tn2, media_fn2 = Clasificador.validacion(validacion_cruzada_tic,datos_tic,True)\n",
    "\n",
    "#  GERMAN  \n",
    "# Validacion con validacion simple\n",
    "media_error3, media_tp3, media_fp3, media_tn3, media_fn3 = Clasificador.validacion(validacion_simple_ger,datos_ger,True)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error4, media_tp4, media_fp4, media_tn4, media_fn4 = Clasificador.validacion(validacion_cruzada_ger,datos_ger,True)\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados_con = [[round(media_error1, 3), round(media_error3, 3)], [round(media_error2, 3), \n",
    "round(media_error4, 3)]]\n",
    "print(\"Con Laplace\")\n",
    "print(tabulate(resultados_con, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Como se puede observar en las tablas generadas, se cumple lo dicho en el apartado anterior, \n",
    " siendo el error medio de la validación cruzada más bajo que el de la simple. De lo cual se puede deducir que la validación cruzada es más precisa.\n",
    "\n",
    " Del mismo modo, podemos observar que en ambos tipos de validación, el error medio de 'german.data' es inferior al de tic-tac-toe'. Esto se debe a que, al tener más ejemplos con los que entrenar, el modelo es más preciso y clasifica mejor los ejemplos de train.\n",
    "\n",
    " Por último, en estos datasets pequeños, no se aprecia una gran diferencia entre la ejecición sin y con la correccion de Laplace. Esto se debe a que para mostrar los datos, se han redondeado a 3 decimales, sin embargo, si nos fijasemos en más decimales, veríamos que con la corrección el error es sutilmente más pequeño.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aparto 3 => Scikit-Learn\n",
    "Incluir los mismos resultados que en el apartado 2 pero usando los\n",
    "métodos del paquete scikit-learn. Comparar y analizar los resultados. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    " Para llevar a cabo la verificación de nuestros clasificadores implementados usamos la libreria scikitlearn, \n",
    " de la cual usamos varias funciones de clasificación, varias de metodos de validación y varias de preprocesado de datos.\n",
    " Para empezar, hemos desarrollado dos funciones propias de la clase abstracta Verificador, \n",
    " las cuales se encargana de llevar a cabo un preprocesado similar al que desarrollamos en la primera entrega, \n",
    " y por otra parte hemos desarrollado un preprocesado OneHot que nos ha proporcionado muy buenos resultados. \n",
    " \n",
    " Por otro lado, implementamos una función muy pequeña que se encarga de separar los datos de entrada y los de clasificación\n",
    " y almacenarnos en estructuras diferentes. \n",
    " Por último, como funciones abstractas desarrollamos dos métodos de validación (validación simple y validación cruzada).\n",
    "\n",
    " En cuanto a las subclases que encontramos, hemos decidido implementar tanto el clasififcador GaussianNB como el MultinominalNB. \n",
    " Ambas se pueden configurar mediante hiperparametros, y aunque ambas nos han devuelto resultados muy buenos \n",
    " en la siguiente implementación hemos decidido usar únicamente el GaussianNB, puesto que es el que mejor ha \n",
    " respondido a los datasets proporcinados.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgNB = Verificador_GaussianNB()\n",
    "# GaussianNB => Sin Preprocesado\n",
    "#     TIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\n",
    "tic_simple_sin = vgNB.clasificate(prepro=False,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "#     TIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\n",
    "tic_cruzada_sin = vgNB.clasificate(prepro=False,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "\n",
    "#     GERMAN => Validacion Simple (TRAIN=0.75)\n",
    "german_simple_sin = vgNB.clasificate(prepro=False,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/german.data\")\n",
    "#     GERMAN => Validacion Cruzada (KFOLDS = 6)\n",
    "german_cruzada_sin = vgNB.clasificate(prepro=False,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/german.data\")\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados_sk_sin = [[round(tic_simple_sin, 3), round(german_simple_sin, 3)], [round(tic_cruzada_sin, 3), round(german_cruzada_sin, 3)]]\n",
    "\n",
    "\n",
    "\n",
    "# GaussianNB => Con Preprocesado\n",
    "\n",
    "#     TIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\n",
    "tic_simple_con = vgNB.clasificate(prepro=True,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "#     TIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\n",
    "tic_cruzada_con = vgNB.clasificate(prepro=True,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "\n",
    "#     GERMAN => Validacion Simple (TRAIN=0.75)\n",
    "german_simple_con = vgNB.clasificate(prepro=True,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/german.data\")\n",
    "#     GERMAN => Validacion Cruzada (KFOLDS = 6)\n",
    "german_cruzada_con = vgNB.clasificate(prepro=True,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/german.data\")\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados_sk_con = [[round(tic_simple_con, 3), round(german_simple_con, 3)], [round(tic_cruzada_con, 3), round(german_cruzada_con, 3)]]\n",
    "\n",
    "# Impresion de las tablas\n",
    "print(\"Practica 1:\")\n",
    "print(\" Sin Laplace\")\n",
    "print(tabulate(resultados_sin, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n",
    "print(\" Con Laplace\")\n",
    "print(tabulate(resultados_con, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n",
    "\n",
    "print(\"\\nSKLearn:\")\n",
    "print(\" Sin Preprocesado\")\n",
    "print(tabulate(resultados_sk_sin, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n",
    "print(\" Con Preprocesado\")\n",
    "print(tabulate(resultados_sk_con, headers=['Tasa de error', 'Tic-Tac-Toe','German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Para validar los resultados debemos conocer la importancia y efectividad del preprocesado OneHot, ideal para tablas\n",
    " dataset's que albergan pocas columnas. Este tipo de preprocesado usa las columnas y sus posibles valores para reconstruir el\n",
    " dataset con tantas columnas como [Sumatorio{Columna(i) * #Valores(Columna(i))}]. Esto nos permite que teniendo el mismo\n",
    " numero de entradas en el dataset, podamos tener una codificacion mucho más concreta y por ende facilitemos la labor al\n",
    " clasificador puesto que ahora las entradas se codifican de modo binario. \n",
    " \n",
    " Conociendo esta situación vemos como todas aquellas pruebas realizadas tanto en un fichero como en otro, son mucho\n",
    " mejores que sin aplicar un preprocesado OneHot. Por otra parte vemos como la validación simple es mucho mejor en cuanto\n",
    " al error medio presentado con validacion cruzada y además vemos que la clasificación en general se realiza de mejor manera\n",
    " para el fichero tic-tac-toe.dat que para el fichero german.data, posiblemente porque este ultimo contiene más registros\n",
    " y más columnas.\n",
    " \n",
    " Como hiperparametros, hemos empleado 0.75 para el entrenamiento en validación simple y 6 Kfolds para validación cruzada.\n",
    " En cuanto al primero, consideramos un porcentaje de entrenamiento lo suficientemente grande como para no sobreestimar en\n",
    " la clasififcación y para asi garantizar esa capacidad de geeneralizar frente los datos a clasificar.\n",
    " \n",
    " En cuanto al segundo hiperparametro lo consideramos algo pequeño, para estos dataset. Hemos probado a aumentar este número\n",
    " de bloques y hemos observado que a medida que aumentaba el error medio disminuia. Podemos afirmar, que para tic-tac-toe.data\n",
    " un \"correcto\" número de carpetas sería 12, mientras que para german.data este sería de 10 carpetas.\n",
    " \n",
    " Aún con estas modificaciones, error nos disminuye considerablemente, pero si consideramos un método de estimar cuantas\n",
    " carpetas son necesarias dado el volumen y las condiciones de un dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 4 => Evaluación de hipótesis mediante Análisis ROC\n",
    "Matriz de confusión y diagramas del clasificador en el espacio ROC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "La matriz de confusión toma los valores medios de las ejecuciones del modelo con correccion de Laplace, tanto las de validación simple como las de cruzada. Con ella, podemos comprobar de una manera mucho más precisa la precisión de nuestro modelo. Se pueden ver los aciertos y los fallos que ha tenido al clasificar la clase 1 como 2 y viceversa. El formato escogido el es siguiente:\n",
    "\n",
    "TPR FPR\n",
    "FNR TNR\n",
    "\n",
    "De esta forma, de un vistazo a la diagonal normal se pueden ver los aciertos que hemos tenido.\n",
    "\n",
    "En cuanto al espacio ROC, es una forma más visual de comprobar el comportamiento del modelo. Hemos generado también una recta entre (0,0) y (1,1) con el fin de que, de un vistazo, se pueda ver el nivel de aciertos y de fallos. Si el punto generado está por encima de la recta, el modelo acierta más que falla, por lo tanto de podría decir que es un buen modelo. Si, por el contrario, el punto se encuentra por debajo de la recta, nuestro modelo falla más que acierta y, en consecuencia, no sería válido. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la media de las tasas de val. simple y val. cruzada para la matriz de confusion media\n",
    "    mx1 = MatrizConfusion()\n",
    "\n",
    "    # TIC-TAC-TOE\n",
    "    print(\"\\nTic-Tac-Toe\\n\")\n",
    "    tpr, fpr = mx1.matrix_media(media_tp1, media_tp2, media_fp1, media_fp2, \n",
    "                    media_tn1, media_tn2, media_fn1, media_fn2)\n",
    "    plot_points = [[fpr, tpr, 'NB']]\n",
    "    mx1.plot(plot_points, \"tic-tac-toe\")\n",
    "\n",
    "    # GERMAN\n",
    "    print(\"\\nGerman\\n\")\n",
    "\n",
    "    tpr, fpr = mx1.matrix_media(media_tp3, media_tp4, media_fp3, media_fp4, \n",
    "                    media_tn3, media_tn4, media_fn3, media_fn4)\n",
    "    plot_points = [[fpr, tpr, 'NB']]\n",
    "    mx1.plot(plot_points, \"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En cuanto a la matriz de confusión, podemos observar que en ambos casos la clase positiva es mucho más abundante en el dataset que la negativa, por tanto los números de la primera fila son más altos. Sin embargo, cabe destacar que la cantidad de aciertos en ambas es bastante mayor que el de fallos,lo que se traduce en una predicción por encima de la diagonal normal.\n",
    "\n",
    "Se observa también que el porcentaje de aciertos/fallos de la clase 1 (positiva) es mucho menor que el de la clase 2 (negativa). Esto se debe a que, como se ha mencionado anteriormente, en el dataset existen más ejemplos de la primera clase que de la segunda y como consecuencia, el modelo se encuentra mejor entrenado en la clase positiva y acierta más en esta. \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}