{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2042f24db98b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMatrizConfusion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatrizConfusion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "from Datos import Datos\n",
    "from EstrategiaParticionado import ValidacionSimple\n",
    "from EstrategiaParticionado import ValidacionCruzada\n",
    "from Clasificador import ClasificadorNaiveBayes,Clasificador\n",
    "from Verificador import Verificador_GaussianNB, Verificador_Multinominal\n",
    "from MatrizConfusion import MatrizConfusion\n",
    "\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 1 => Particionado\n",
    "\n",
    "Análisis de las dos estrategias de particionado propuestas: simple, y\n",
    "cruzada, para los conjuntos propuestos: german y tic-tac-toe. El análisis\n",
    "consiste en una descripción de los índices de train y test devueltos por\n",
    "cada uno de los métodos de particionado, junto con un comentario\n",
    "sobre las ventajas/desventajas de cada uno de ellos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En cuanto al metodo de VALIDACIÓN SIMPLE es el mas sencillo de implementar, puesto que se basa en una division \n",
    "aleatoria en dos grupos. Sin embargo, aún siendo el modo de validación más sencillo, trae consigo una serie de\n",
    "inconvenientes:\n",
    "    \n",
    "    1) El ratio de error, es altamente variable dependiendo de las instancias del dataset escogido, para \n",
    "    entrenamiento, y test.\n",
    "    \n",
    "    2) Al segregar una serie de instancias para entrenamiento y test, estamos provocando que durante el entrenamiento\n",
    "    el clasificador, no contemple todas las posibles situaciones de un contexto, por lo tanto esto produce\n",
    "    una sobrestimación del ratio de error.\n",
    "    \n",
    "Por su parte el método de VALIDACIÓN CRUZADA es más complejo de implementar, puesto que se trata de un proceso \n",
    "iterativo. Éste, busca dividir todo el conjunto de datos en k grupos, de tal modo que, solo uno de esos bloques se usa \n",
    "como test, mientras que el resto de divisiones se usan como entrenamiento. Por cada iteración se turnan los \"roles\", de \n",
    "tal modo, que todas las subdivisiones son testadas y todas han sido usadas como entrenamiento. \n",
    "\n",
    "En un escenario, en el que el conjunto de datos es pequeño, es muy superior a validacón simple y otra ventaja \n",
    "respecto a validación simple es que, prueba y valida todas las instancias de datos. Por otra parte, podemos decir que\n",
    "el ratio de error en este tipo de validacion es mucho más preciso y real, puesto que se entrena con prácticamente todo\n",
    "el conjunto de datos maximizando asi el modelo sin sobrestimar en las predicciones. A su vez, es de gran\n",
    "utilidad el que el ratio de error sea calculado como un promedio de las estimaciones de cada iteración.\n",
    "\n",
    "Respecto los inconvenientes, principalmente encontramos uno, que es el coste computacional que requiere este método.\n",
    "La identificación de bloques, el número de iteraciones y sobre todo que en el caso de usar un dataset \n",
    "excesivamente grande, debemos contemplar la posibilidad de que se vuelva algo lento y costoso (en comparación con\n",
    "validación simple) y por tanto no sea tan útil como en otras circunstancias.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## VALIDACION SIMPLE TIC-TAC-TOE ########\n",
      "Porcentaje entrenamiento: 75\n",
      "Numero iteraciones: 10 <=> Numero particiones: 10\n",
      "Indices Totales(Primera Iteracion/Particion) => 958\n",
      "\tNum Indices Train: 719\n",
      "\tNum Indices Test: 239\n",
      "\n",
      "######## VALIDACION CRUZADA TIC-TAC-TOE ########\n",
      "Numero Carpetas: 6 <=> Numero particiones: 6\n",
      "Indices Totales(Primera Iteracion/Particion) => 958\n",
      "\tNum Indices Train: 798\n",
      "\tNum Indices Test: 160\n",
      "\n",
      "######## VALIDACIONES GERMAN ########\n",
      "Porcentaje entrenamiento: 75\n",
      "Numero iteraciones: 10 <=> Numero particiones: 10\n",
      "Indices Totales(Primera Iteracion/Particion) => 1000\n",
      "\tNum Indices Train: 750\n",
      "\tNum Indices Test: 250\n",
      "\n",
      "######## VALIDACION CRUZADA GERMAN ########\n",
      "Numero Carpetas: 6 <=> Numero particiones: 6\n",
      "Indices Totales(Primera Iteracion/Particion) => 1000\n",
      "\tNum Indices Train: 833\n",
      "\tNum Indices Test: 167\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cambiar y poner bonito, pero lo necesito para el 2\"\"\"\n",
    "\n",
    "fileName = \"ConjuntosDatos/tic-tac-toe.data\"\n",
    "datos_tic = Datos(fileName)\n",
    "    \n",
    "    # Probamos con 75 porciento y 10 iteraciones (Validacion Simple)\n",
    "validacion_simple_tic = ValidacionSimple(75,10)\n",
    "aux_simple_tic = validacion_simple_tic.creaParticiones(datos_tic)\n",
    "\n",
    "print(\"######## VALIDACION SIMPLE TIC-TAC-TOE ########\")\n",
    "print(\"Porcentaje entrenamiento: \" + str(validacion_simple_tic.porcentaje))\n",
    "print(\"Numero iteraciones: \" + str(validacion_simple_tic.numEjecuciones) + \" <=> Numero particiones: \" + str(len(aux_simple_tic)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_tic.cantidadDatos))\n",
    "print(\"\\tNum Indices Train: \" + str(len(aux_simple_tic[0].indicesTrain)))\n",
    "print(\"\\tNum Indices Test: \" + str(len(aux_simple_tic[0].indicesTest)))\n",
    "\n",
    "    # Probamos con 10 k-iteraciones\n",
    "validacion_cruzada_tic = ValidacionCruzada(6)\n",
    "aux_cruzada_tic = validacion_cruzada_tic.creaParticiones(datos_tic)\n",
    "\n",
    "print(\"\\n######## VALIDACION CRUZADA TIC-TAC-TOE ########\")\n",
    "print(\"Numero Carpetas: \" + str(validacion_cruzada_tic.numParticiones) + \" <=> Numero particiones: \" + str(len(aux_cruzada_tic)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_tic.cantidadDatos))\n",
    "print(\"\\tNum Indices Train: \" + str(len(aux_cruzada_tic[0].indicesTrain)))\n",
    "print(\"\\tNum Indices Test: \" + str(len(aux_cruzada_tic[0].indicesTest)))\n",
    "\n",
    "fileName = \"ConjuntosDatos/german.data\"\n",
    "datos_ger = Datos(fileName)\n",
    "\n",
    "    # Probamos con 75 porciento y 10 iteraciones (Validacion Simple)\n",
    "validacion_simple_ger = ValidacionSimple(75,10)\n",
    "aux_simple_ger = validacion_simple_ger.creaParticiones(datos_ger)\n",
    "\n",
    "print(\"\\n######## VALIDACIONES GERMAN ########\")\n",
    "print(\"Porcentaje entrenamiento: \" + str(validacion_simple_ger.porcentaje))\n",
    "print(\"Numero iteraciones: \" + str(validacion_simple_ger.numEjecuciones) + \" <=> Numero particiones: \" + str(len(aux_simple_ger)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_ger.cantidadDatos))\n",
    "print(\"\\tNum Indices Train: \" + str(len(aux_simple_ger[0].indicesTrain)))\n",
    "print(\"\\tNum Indices Test: \" + str(len(aux_simple_ger[0].indicesTest)))\n",
    "\n",
    "# Probamos con 10 k-iteraciones\n",
    "validacion_cruzada_ger = ValidacionCruzada(6)\n",
    "aux_cruzada_ger = validacion_cruzada_ger.creaParticiones(datos_ger)\n",
    "print(\"\\n######## VALIDACION CRUZADA GERMAN ########\")\n",
    "print(\"Numero Carpetas: \" + str(validacion_cruzada_ger.numParticiones) + \" <=> Numero particiones: \" + str(len(aux_cruzada_ger)))\n",
    "print(\"Indices Totales(Primera Iteracion/Particion) => \" + str(datos_ger.cantidadDatos))\n",
    "print(\"\\tNum Indices Train: \" + str(len(aux_cruzada_ger[0].indicesTrain)))\n",
    "print(\"\\tNum Indices Test: \" + str(len(aux_cruzada_ger[0].indicesTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Como vemos, hemos representado dos particiones para cada dataset empleado en la práctica.\n",
    "Las validaciones simples hemos almacenado el numero de iteraciones que para ambas pruebas ha sido de 10.\n",
    "En cada iteración, que corresponde a su vez a una particion, almacenamos de modo aleatorio el número de indices \n",
    "especificado por el usuario en forma de porcentaje (para nuestro ejemplo, se trata de un 0.75).\n",
    "\n",
    "En cuanto a la validación cruzada, preparamos a priori, cada bloque con el número de indices que le corresponde.\n",
    "Para el caso de tic-tac-toe.data, estamos usando un total de 958 entradas en el datset que se reparten entre 6 bloques\n",
    "con 158-160 indices. Como vemos el número de indices varia, dependiendo de la situación y de si el total de indices, es\n",
    "divisible (con resto 0) wntre el número de bloques (Kfolds) que escogio el usuario.\n",
    "\n",
    "Tras ello, procedemos a insertar los indices de cada bloque en los array's de indicesTrain, e indicesTest, y tenemos en\n",
    "cuenta, que bloque ha sido de test en cada iteración, para en cada una, escoger uno diferente y asignar el resto de\n",
    "bloques como datos de train.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 2 => Naive Bayes\n",
    "\n",
    "Tabla con los resultados de la ejecución para los conjuntos de datos\n",
    "analizados (tic-tac-toe y german). Considerar los dos tipos de\n",
    "particionado.\n",
    "Los resultados se refieren a las tasas de error/acierto y deben incluirse\n",
    "tanto con la corrección de Laplace como sin ella. Se debe incluir tanto\n",
    "el promedio de error para las diferentes particiones como su desviación\n",
    "típica. Es importante mostrar todos los resultados agrupados en una\n",
    "tabla para facilitar su evaluación.\n",
    "Breve análisis de los resultados anteriores.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Como se puede observar en las tablas generadas, se cumple lo dicho en el apartado anterior, \n",
    " siendo el error medio de la validación cruzada más bajo que el de la simple. De lo cual se puede deducir que la \n",
    " validación cruzada es más precisa.\n",
    "\n",
    " Además, cabe destacar las diferencias entre ejecutar, la validación sin y con la corrección de Laplace. \n",
    " En estos datasets pequeños, no parece que se aprecie mucha diferencia, pero si nos fijamos en la validación cruzada,\n",
    " veremos que en 'German' sí que nos cambia, subiendo un poco la tasa de error medio. \n",
    " Esto puede ser causado por la generación de ejemplos que no se encuentran en el dataset que realiza la corrección \n",
    " de Laplace para eliminar valores nulos de las tablas de atributos.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin Laplace\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tabulate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6a9609e4faaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sin Laplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultados\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tasa de error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Tic-Tac-Toe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'German'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshowindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Val. Simple'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Val. Cruzada'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtablefmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fancy_grid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#       Con Laplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabulate' is not defined"
     ]
    }
   ],
   "source": [
    "# Creacion del clasificador\n",
    "Clasificador = ClasificadorNaiveBayes()\n",
    "\n",
    "#       Sin Laplace\n",
    "#  TIC-TAC-TOE\n",
    "# Validacion con validacion simple\n",
    "media_error1, media_tp1, media_fp1, media_tn1, media_fn1 = Clasificador.validacion(validacion_simple_tic,datos_tic,False)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error2, media_tp2, media_fp2, media_tn2, media_fn2 = Clasificador.validacion(validacion_cruzada_tic,datos_tic,False)\n",
    "\n",
    "#  GERMAN  \n",
    "# Validacion con validacion simple\n",
    "media_error3, media_tp3, media_fp3, media_tn3, media_fn3 = Clasificador.validacion(validacion_simple_ger,datos_ger,False)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error4, media_tp4, media_fp4, media_tn4, media_fn4 = Clasificador.validacion(validacion_cruzada_ger,datos_ger,False)\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados = [[round(media_error1, 3), round(media_error3, 3)], [round(media_error2, 3), \n",
    "round(media_error4, 3)]]\n",
    "\n",
    "print(\"Sin Laplace\")\n",
    "print(tabulate(resultados, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n",
    "\n",
    "#       Con Laplace\n",
    "#  TIC-TAC-TOE\n",
    "# Validacion con validacion simple\n",
    "media_error1, media_tp1, media_fp1, media_tn1, media_fn1 = Clasificador.validacion(validacion_simple_tic,datos_tic,True)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error2, media_tp2, media_fp2, media_tn2, media_fn2 = Clasificador.validacion(validacion_cruzada_tic,datos_tic,True)\n",
    "\n",
    "#  GERMAN  \n",
    "# Validacion con validacion simple\n",
    "media_error3, media_tp3, media_fp3, media_tn3, media_fn3 = Clasificador.validacion(validacion_simple_ger,datos_ger,True)\n",
    "\n",
    "# Validacion con validacion cruzada\n",
    "media_error4, media_tp4, media_fp4, media_tn4, media_fn4 = Clasificador.validacion(validacion_cruzada_ger,datos_ger,True)\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados = [[round(media_error1, 3), round(media_error3, 3)], [round(media_error2, 3), \n",
    "round(media_error4, 3)]]\n",
    "print(\"Con Laplace\")\n",
    "print(tabulate(resultados, headers=['Tasa de error', 'Tic-Tac-Toe', 'German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aparto 3 => Scikit-Learn\n",
    "Incluir los mismos resultados que en el apartado 2 pero usando los\n",
    "métodos del paquete scikit-learn. Comparar y analizar los resultados. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    " Para llevar a cabo la verificación de nuestros clasificadores implementados usamos la libreria scikitlearn, \n",
    " de la cual usamos varias funciones de clasificación, varias de metodos de validación y varias de preprocesado de datos.\n",
    " Para empezar, hemos desarrollado dos funciones propias de la clase abstracta Verificador, \n",
    " las cuales se encargana de llevar a cabo un preprocesado similar al que desarrollamos en la primera entrega, \n",
    " y por otra parte hemos desarrollado un preprocesado OneHot que nos ha proporcionado muy buenos resultados. \n",
    " \n",
    " Por otro lado, implementamos una función muy pequeña que se encarga de separar los datos de entrada y los de clasificación\n",
    " y almacenarnos en estructuras diferentes. \n",
    " Por último, como funciones abstractas desarrollamos dos métodos de validación (validación simple y validación cruzada).\n",
    "\n",
    " En cuanto a las subclases que encontramos, hemos decidido implementar tanto el clasififcador GaussianNB como el MultinominalNB. \n",
    " Ambas se pueden configurar mediante hiperparametros, y aunque ambas nos han devuelto resultados muy buenos \n",
    " en la siguiente implementación hemos decidido usar únicamente el GaussianNB, puesto que es el que mejor ha \n",
    " respondido a los datasets proporcinados.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB => Sin Preprocesad\n",
      "\n",
      "\tTIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\n",
      "\tVerificador GaussianNB ==> Error medio Simple (0.291667) en archivo ConjuntosDatos/tic-tac-toe.data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() should return None, not 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8fb70b2550c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     TIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\tTIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtic_simple_sin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVerificador_GaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepro\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtipo_validacion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mporcentaje\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marchivo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ConjuntosDatos/tic-tac-toe.data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#     TIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\tTIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() should return None, not 'float'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# GaussianNB => Sin Preprocesado\n",
    "print(\"GaussianNB => Sin Preprocesad\")\n",
    "#     TIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\n",
    "print(\"\\n\\tTIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\")\n",
    "tic_simple_sin = Verificador_GaussianNB(prepro=False,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "#     TIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\n",
    "print(\"\\n\\tTIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\")\n",
    "tic_cruzada_sin = Verificador_GaussianNB(prepro=False,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "\n",
    "#     GERMAN => Validacion Simple (TRAIN=0.75)\n",
    "print(\"\\n\\tGERMAN => Validacion Cruzada (TRAIN = 0.75)\")\n",
    "german_simple_sin = Verificador_GaussianNB(prepro=False,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/german.data\")\n",
    "#     GERMAN => Validacion Cruzada (KFOLDS = 6)\n",
    "print(\"\\n\\tGERMAN => Validacion Cruzada (KFOLDS = 6)\")\n",
    "german_cruzada_sin = Verificador_GaussianNB(prepro=False,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/german.data\")\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados = [[round(tic_simple_sin, 3), [round(german_simple_sin, 3), round(tic_cruzada_sin, 3)], round(german_cruzada_sin, 3)]]\n",
    "print(\"Sin Preprocesado\")\n",
    "print(tabulate(resultados, headers=['Tic-Tac-Toe','German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n",
    "\n",
    "\n",
    "# GaussianNB => Con Preprocesado\n",
    "\n",
    "#     TIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\n",
    "print(\"\\n\\tTIC-TAC-TOE => Validacion Simple (TRAIN=0.75)\")\n",
    "tic_simple_con = Verificador_GaussianNB(prepro=True,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "#     TIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\n",
    "print(\"\\n\\tTIC-TAC-TOE => Validacion Cruzada (KFOLDS = 6)\")\n",
    "tic_cruzada_con = Verificador_GaussianNB(prepro=True,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "\n",
    "#     GERMAN => Validacion Simple (TRAIN=0.75)\n",
    "print(\"\\n\\tGERMAN => Validacion Cruzada (TRAIN = 0.75)\")\n",
    "german_simple_con = Verificador_GaussianNB(prepro=True,tipo_validacion=1,porcentaje=0.75,folds=3,archivo=\"ConjuntosDatos/german.data\")\n",
    "#     GERMAN => Validacion Cruzada (KFOLDS = 6)\n",
    "print(\"\\n\\tGERMAN => Validacion Cruzada (KFOLDS = 6)\")\n",
    "german_cruzada_con = Verificador_GaussianNB(prepro=True,tipo_validacion=2,porcentaje=0.75,folds=6,archivo=\"ConjuntosDatos/german.data\")\n",
    "\n",
    "# Impresion de los resultados\n",
    "resultados = [[round(tic_simple_con, 3), [round(german_simple_con, 3), round(tic_cruzada_con, 3)], round(german_cruzada_con, 3)]]\n",
    "print(\"Con Preprocesado\")\n",
    "print(tabulate(resultados, headers=['Tic-Tac-Toe','German'], showindex=['Val. Simple', 'Val. Cruzada'], tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n Para validar los resultados debemos conocer la importancia y efectividad del preprocesado OneHot, ideal para tablas\\n dataset\\'s que albergan pocas columnas. Este tipo de preprocesado usa las columnas y sus posibles valores para reconstruir el\\n dataset con tantas columnas como [Sumatorio{Columna(i) * #Valores(Columna(i))}]. Esto nos permite que teniendo el mismo\\n numero de entradas en el dataset, podamos tener una codificacion mucho más concreta y por ende facilitemos la labor al\\n clasificador puesto que ahora las entradas se codifican de modo binario. \\n \\n Conociendo esta situación vemos como todas aquellas pruebas realizadas tanto en un fichero como en otro, son mucho\\n mejores que sin aplicar un preprocesado OneHot. Por otra parte vemos como la validación simple es mucho mejor en cuanto\\n al error medio presentado con validacion cruzada y además vemos que la clasificación en general se realiza de mejor manera\\n para el fichero tic-tac-toe.dat que para el fichero german.data, posiblemente porque este ultimo contiene más registros\\n y más columnas.\\n \\n Como hiperparametros, hemos empleado 0.75 para el entrenamiento en validación simple y 6 Kfolds para validación cruzada.\\n En cuanto al primero, consideramos un porcentaje de entrenamiento lo suficientemente grande como para no sobreestimar en\\n la clasififcación y para asi garantizar esa capacidad de geeneralizar frente los datos a clasificar.\\n \\n En cuanto al segundo hiperparametro lo consideramos algo pequeño, para estos dataset. Hemos probado a aumentar este número\\n de bloques y hemos observado que a medida que aumentaba el error medio disminuia. Podemos afirmar, que para tic-tac-toe.data\\n un \"correcto\" número de carpetas sería 12, mientras que para german.data este sería de \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " Para validar los resultados debemos conocer la importancia y efectividad del preprocesado OneHot, ideal para tablas\n",
    " dataset's que albergan pocas columnas. Este tipo de preprocesado usa las columnas y sus posibles valores para reconstruir el\n",
    " dataset con tantas columnas como [Sumatorio{Columna(i) * #Valores(Columna(i))}]. Esto nos permite que teniendo el mismo\n",
    " numero de entradas en el dataset, podamos tener una codificacion mucho más concreta y por ende facilitemos la labor al\n",
    " clasificador puesto que ahora las entradas se codifican de modo binario. \n",
    " \n",
    " Conociendo esta situación vemos como todas aquellas pruebas realizadas tanto en un fichero como en otro, son mucho\n",
    " mejores que sin aplicar un preprocesado OneHot. Por otra parte vemos como la validación simple es mucho mejor en cuanto\n",
    " al error medio presentado con validacion cruzada y además vemos que la clasificación en general se realiza de mejor manera\n",
    " para el fichero tic-tac-toe.dat que para el fichero german.data, posiblemente porque este ultimo contiene más registros\n",
    " y más columnas.\n",
    " \n",
    " Como hiperparametros, hemos empleado 0.75 para el entrenamiento en validación simple y 6 Kfolds para validación cruzada.\n",
    " En cuanto al primero, consideramos un porcentaje de entrenamiento lo suficientemente grande como para no sobreestimar en\n",
    " la clasififcación y para asi garantizar esa capacidad de geeneralizar frente los datos a clasificar.\n",
    " \n",
    " En cuanto al segundo hiperparametro lo consideramos algo pequeño, para estos dataset. Hemos probado a aumentar este número\n",
    " de bloques y hemos observado que a medida que aumentaba el error medio disminuia. Podemos afirmar, que para tic-tac-toe.data\n",
    " un \"correcto\" número de carpetas sería 12, mientras que para german.data este sería de 10 carpetas.\n",
    " \n",
    " Aún con estas modificaciones, error nos disminuye considerablemente, pero si consideramos un método de estimar cuantas\n",
    " carpetas son necesarias dado el volumen y las condiciones de un dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apartado 4 => Evaluación de hipótesis mediante Análisis ROC\n",
    "Matriz de confusión y diagramas del clasificador en el espacio ROC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En cuanto a la matriz de confusión, podemos observar que en ambos casos la clase positiva es mucho más abundante en el dataset que la negativa, por tanto los números de la primera fila son más altos.\n",
    "\n",
    "En segundo lugar, cabe destacar que la cantidad de aciertos en ambas es bastante mayor que el de fallos,lo que se traduce en una predicción por encima de la diagonal normal.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la media de las tasas de val. simple y val. cruzada para la matriz de confusion media\n",
    "    mx1 = MatrizConfusion()\n",
    "\n",
    "    # TIC-TAC-TOE\n",
    "    print(\"\\nTic-Tac-Toe\\n\")\n",
    "    tpr, fpr = mx1.matrix_media(media_tp1, media_tp2, media_fp1, media_fp2, \n",
    "                    media_tn1, media_tn2, media_fn1, media_fn2)\n",
    "    plot_points = [[fpr, tpr, 'NB']]\n",
    "    mx1.plot(plot_points, \"tic-tac-toe\")\n",
    "\n",
    "    # GERMAN\n",
    "    print(\"\\nGerman\\n\")\n",
    "\n",
    "    tpr, fpr = mx1.matrix_media(media_tp3, media_tp4, media_fp3, media_fp4, \n",
    "                    media_tn3, media_tn4, media_fn3, media_fn4)\n",
    "    plot_points = [[fpr, tpr, 'NB']]\n",
    "    mx1.plot(plot_points, \"german\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
